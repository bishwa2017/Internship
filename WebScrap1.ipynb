{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Wikipedia main Page"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install bs4\r\n",
    "!pip install requests"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from bs4 import BeautifulSoup\r\n",
    "import requests"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "page=requests.get(\"https://en.wikipedia.org/wiki/Main_Page/\")\r\n",
    "page"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "page"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "page.content"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "soup1=BeautifulSoup(page.text,'html.parser')\r\n",
    "soup1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(soup1.prettify())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "story = soup1.find_all(['h1', 'h2','h3'])\r\n",
    "#'h1 Main Page',\r\n",
    "#'h2 From today's featured article\",\r\n",
    "#'h2 Did you know\\xa0...',\r\n",
    "#'h2 In the news',\r\n",
    "for i in story:\r\n",
    "    story.append(i.text)\r\n",
    "    print(story)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install pandas"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "header=pd.DataFrame({})\r\n",
    "header['title']=story\r\n",
    "header.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# IMDB Top 100 Movies"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install lxml\r\n",
    "!pip install numpy\r\n",
    "!pip install html5lib"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import re\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "url=\"https://www.imdb.com/chart/top/\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "page=requests.get(url)\r\n",
    "page"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "page.content"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "soup2 = BeautifulSoup(page.content,\"html.parser\")\r\n",
    "print(soup2.prettify())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "scraped_movies = soup2.find_all('td' , class_='titleColumn')\r\n",
    "scraped_movies"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "movies = []\r\n",
    "for movie in scraped_movies:\r\n",
    "    movie = movie.get_text().replace('\\n',\"\")\r\n",
    "    movie = movie.strip(\" \")\r\n",
    "    movies.append(movie)\r\n",
    "movies"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "scraped_ratings = soup2.find_all('td', class_='ratingColumn imdbRating')\r\n",
    "scraped_ratings"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ratings = []\r\n",
    "for rating in scraped_ratings:\r\n",
    "    rating = rating.get_text().replace('\\n', \"\")\r\n",
    "    rating = rating.strip(\" \")\r\n",
    "    ratings.append(rating)\r\n",
    "ratings"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = pd.DataFrame()\r\n",
    "data[\"Movie Names\"]=movies\r\n",
    "data[\"Ratings\"]=ratings\r\n",
    "data.head(100)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data.to_csv('IMDB Top Movies.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# IMDB Top 100 Indian Movies"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "url = \"https://www.imdb.com/india/top-rated-indian-movies/\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "page = requests.get(url)\r\n",
    "page"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "page.content"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "soup = BeautifulSoup(page.content,\"html.parser\")\r\n",
    "print(soup.prettify())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "scraped_movies = soup.find_all('td' , class_='titleColumn')\r\n",
    "scraped_movies"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "movies = []\r\n",
    "for movie in scraped_movies:\r\n",
    "    movie = movie.get_text().replace('\\n',\"\")\r\n",
    "    movie = movie.strip(\" \")\r\n",
    "    movies.append(movie)\r\n",
    "movies"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "scraped_ratings = soup.find_all('td', class_='ratingColumn imdbRating')\r\n",
    "scraped_ratings"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ratings = []\r\n",
    "for rating in scraped_ratings:\r\n",
    "    rating = rating.get_text().replace('\\n', \"\")\r\n",
    "    rating = rating.strip(\" \")\r\n",
    "    ratings.append(rating)\r\n",
    "ratings"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = pd.DataFrame()\r\n",
    "data[\"Movie Names\"]=movies\r\n",
    "data[\"Ratings\"]=ratings\r\n",
    "data.head(100)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Scrap book name, author name, genre and book review of any 5 books"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "url = \"https://bookpage.com/reviews/\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "page = requests.get(url)\r\n",
    "page"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "soup = BeautifulSoup(page.content,\"html.parser\")\r\n",
    "print(soup.prettify())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "scraped_books = soup.find_all('div', class_=\"flex-article-content\")\r\n",
    "scraped_books"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "books = []\r\n",
    "for book in scraped_books:\r\n",
    "    book = book.get_text().replace('\\n',\"\")\r\n",
    "    book = book.strip(\" \")\r\n",
    "    books.append(book)\r\n",
    "books"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "scraped_author = soup.find_all('p', class_='sans bold')\r\n",
    "scraped_author"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "authors = []\r\n",
    "for author in scraped_author:\r\n",
    "    author = author.get_text().replace('\\n',\"\")\r\n",
    "    author = author.strip(\" \")\r\n",
    "    authors.append(author)\r\n",
    "authors"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "scraped_genre = soup.find_all('p',class_='genre-links hidden-phone')\r\n",
    "scraped_genre"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "genres = []\r\n",
    "for genre in scraped_genre:\r\n",
    "    genre = genre.get_text().replace('\\n',\"\")\r\n",
    "    genre = genre.strip(\" \")\r\n",
    "    genres.append(genre)\r\n",
    "genres"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "scraped_reviews=soup.find_all('p',class_='excerpt')\r\n",
    "scraped_reviews"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "reviews = []\r\n",
    "for review in scraped_reviews:\r\n",
    "    review = review.get_text().replace('\\n',\"\")\r\n",
    "    review = review.strip(\" \")\r\n",
    "    reviews.append(review)\r\n",
    "reviews"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = pd.DataFrame()\r\n",
    "data['Books']=books\r\n",
    "data['Authors']=authors\r\n",
    "data['Genres']=genres\r\n",
    "data['Reiviews']=reviews\r\n",
    "data.head(5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Top ODI Teams"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "url1=\"https://www.icc-cricket.com/rankings/mens/team-rankings/odi/\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "page=requests.get(url1)\r\n",
    "page"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "page.content"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "soup1 = BeautifulSoup(page.content,\"html.parser\")\r\n",
    "print(soup1.prettify())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "table = soup1.find('table', {'class': 'table'})\r\n",
    "\r\n",
    "# create dictionary to hold results\r\n",
    "rankings = {}\r\n",
    "\r\n",
    "# separate first row since it uses different markup than the rest\r\n",
    "position = table.find('td', {'class': 'rankings-block__banner--pos'}).text.strip()\r\n",
    "country_name = table.find('span', {'class': 'u-hide-phablet'}).text.strip()\r\n",
    "matches = table.find('td', {'class': 'rankings-block__banner--matches'}).text.strip()\r\n",
    "points = table.find('td', {'class': 'rankings-block__banner--points'}).text.strip()\r\n",
    "rating = table.find('td', {'class': 'rankings-block__banner--rating u-text-right'}).text.strip()\r\n",
    "rankings[country_name] = {'position': position,\r\n",
    "                          'matches': matches,\r\n",
    "                          'points': points,\r\n",
    "                          'rating': rating}\r\n",
    "\r\n",
    "# for the next rows, use a loop\r\n",
    "for row in table.find_all('tr', {'class': 'table-body'}):\r\n",
    "    position = row.find('td', {'class': 'table-body__cell table-body__cell--position u-text-right'}).text.strip()\r\n",
    "    country_name = row.find('span', {'class': 'u-hide-phablet'}).text.strip()\r\n",
    "    matches = row.find_all('td', {'class': 'table-body__cell u-center-text'})[0].text.strip()\r\n",
    "    points = row.find_all('td', {'class': 'table-body__cell u-center-text'})[1].text.strip()\r\n",
    "    rating = row.find('td', {'class': 'table-body__cell u-text-right rating'}).text.strip()\r\n",
    "    rankings[country_name] = {'position': position,\r\n",
    "                          'matches': matches,\r\n",
    "                          'points': points,\r\n",
    "                          'rating': rating}\r\n",
    "rankings"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.DataFrame(rankings)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Top Batting"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/\"\r\n",
    "page = requests.get(url)\r\n",
    "page"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "page.content"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "soup2 = BeautifulSoup(page.content,\"html.parser\")\r\n",
    "print(soup2.prettify())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "first_data=soup2.find(\"div\",attrs={\"data-cricket-scope\":\"odi\"}).find(\"div\",class_=\"rankings-block__top-player\").get_text(strip=True,separator=\" \").split(\" \")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "other_data=soup2.find(\"div\",attrs={\"data-cricket-scope\":\"odi\"}).find_all(\"tr\",class_=\"table-body\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "final_lst=[]\r\n",
    "final_lst.append(first_data)\r\n",
    "\r\n",
    "for i in other_data:\r\n",
    "    split_lst=i.get_text(strip=True,separator=\" \").split(\" \")\r\n",
    "    final_lst.append(split_lst)\r\n",
    "final_lst"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.DataFrame(final_lst)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bowling Ranking"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "url11=\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\"\r\n",
    "page2=requests.get(url11)\r\n",
    "page2.content"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "soup11 = BeautifulSoup(page2.content,\"html.parser\")\r\n",
    "print(soup11.prettify())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "first_data=soup11.find(\"div\",attrs={\"data-cricket-scope\":\"odi\"}).find(\"div\",class_=\"rankings-block__top-player\").get_text(strip=True,separator=\" \").split(\" \")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "other_data=soup11.find(\"div\",attrs={\"data-cricket-scope\":\"odi\"}).find_all(\"tr\",class_=\"table-body\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "final_lst=[]\r\n",
    "final_lst.append(first_data)\r\n",
    "\r\n",
    "for i in other_data:\r\n",
    "    split_lst=i.get_text(strip=True,separator=\" \").split(\" \")\r\n",
    "    final_lst.append(split_lst)\r\n",
    "final_lst"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.DataFrame(final_lst)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Allrounder Ranking"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "url10=\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/all-rounder\"\r\n",
    "page3=requests.get(url10)\r\n",
    "page3.content"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "soup10 = BeautifulSoup(page3.content,\"html.parser\")\r\n",
    "print(soup10.prettify())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "first_data=soup10.find(\"div\",attrs={\"data-cricket-scope\":\"odi\"}).find(\"div\",class_=\"rankings-block__top-player\").get_text(strip=True,separator=\" \").split(\" \")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "other_data=soup10.find(\"div\",attrs={\"data-cricket-scope\":\"odi\"}).find_all(\"tr\",class_=\"table-body\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "final_lst=[]\r\n",
    "final_lst.append(first_data)\r\n",
    "\r\n",
    "for i in other_data:\r\n",
    "    split_lst=i.get_text(strip=True,separator=\" \").split(\" \")\r\n",
    "    final_lst.append(split_lst)\r\n",
    "final_lst"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.DataFrame(final_lst)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Question  6 Womens Team Ranking"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "url6=\"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\"\r\n",
    "page6 = requests.get(url6)\r\n",
    "page6"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "soup6 = BeautifulSoup(page6.content,\"html.parser\")\r\n",
    "print(soup6.prettify())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "table = soup6.find('table', {'class': 'table'})\r\n",
    "\r\n",
    "# create dictionary to hold results\r\n",
    "rankings = {}\r\n",
    "\r\n",
    "# separate first row since it uses different markup than the rest\r\n",
    "position = table.find('td', {'class': 'rankings-block__banner--pos'}).text.strip()\r\n",
    "country_name = table.find('span', {'class': 'u-hide-phablet'}).text.strip()\r\n",
    "matches = table.find('td', {'class': 'rankings-block__banner--matches'}).text.strip()\r\n",
    "points = table.find('td', {'class': 'rankings-block__banner--points'}).text.strip()\r\n",
    "rating = table.find('td', {'class': 'rankings-block__banner--rating u-text-right'}).text.strip()\r\n",
    "rankings[country_name] = {'position': position,\r\n",
    "                          'matches': matches,\r\n",
    "                          'points': points,\r\n",
    "                          'rating': rating}\r\n",
    "\r\n",
    "# for the next rows, use a loop\r\n",
    "for row in table.find_all('tr', {'class': 'table-body'}):\r\n",
    "    position = row.find('td', {'class': 'table-body__cell table-body__cell--position u-text-right'}).text.strip()\r\n",
    "    country_name = row.find('span', {'class': 'u-hide-phablet'}).text.strip()\r\n",
    "    matches = row.find_all('td', {'class': 'table-body__cell u-center-text'})[0].text.strip()\r\n",
    "    points = row.find_all('td', {'class': 'table-body__cell u-center-text'})[1].text.strip()\r\n",
    "    rating = row.find('td', {'class': 'table-body__cell u-text-right rating'}).text.strip()\r\n",
    "    rankings[country_name] = {'position': position,\r\n",
    "                          'matches': matches,\r\n",
    "                          'points': points,\r\n",
    "                          'rating': rating}\r\n",
    "rankings"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.DataFrame(rankings)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Womens Bating Ranking"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "u = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\"\r\n",
    "p = requests.get(u)\r\n",
    "p"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "soup3 = BeautifulSoup(p.content,\"html.parser\")\r\n",
    "print(soup3.prettify())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "first_data=soup3.find(\"div\",attrs={\"data-cricket-scope\":\"odi\"}).find(\"div\",class_=\"rankings-block__top-player\").get_text(strip=True,separator=\" \").split(\" \")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "other_data=soup3.find(\"div\",attrs={\"data-cricket-scope\":\"odi\"}).find_all(\"tr\",class_=\"table-body\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "final_lst=[]\r\n",
    "final_lst.append(first_data)\r\n",
    "\r\n",
    "for i in other_data:\r\n",
    "    split_lst=i.get_text(strip=True,separator=\" \").split(\" \")\r\n",
    "    final_lst.append(split_lst)\r\n",
    "final_lst"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.DataFrame(final_lst)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Allrounder Ranking"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "url9=\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/bowling\"\r\n",
    "page4=requests.get(url9)\r\n",
    "page4.content"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "soup9 = BeautifulSoup(page4.content,\"html.parser\")\r\n",
    "print(soup9.prettify())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "first_data=soup9.find(\"div\",attrs={\"data-cricket-scope\":\"odi\"}).find(\"div\",class_=\"rankings-block__top-player\").get_text(strip=True,separator=\" \").split(\" \")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "other_data=soup9.find(\"div\",attrs={\"data-cricket-scope\":\"odi\"}).find_all(\"tr\",class_=\"table-body\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "final_lst=[]\r\n",
    "final_lst.append(first_data)\r\n",
    "\r\n",
    "for i in other_data:\r\n",
    "    split_lst=i.get_text(strip=True,separator=\" \").split(\" \")\r\n",
    "    final_lst.append(split_lst)\r\n",
    "final_lst"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.DataFrame(final_lst)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Question 7 Amazon Product"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "url7=\"https://www.amazon.in/s?k=mobile+under+20000&ref=nb_sb_noss_2\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "page=requests.get(url7)\r\n",
    "page"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "page.content"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "soup7 = BeautifulSoup(page.content,\"html.parser\")\r\n",
    "print(soup7.prettify())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "product = soup7.find_all('div',class_=\"sg-row\")\r\n",
    "product"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "products = []\r\n",
    "for i in product:\r\n",
    "    i = i.get_text().replace('\\n',\"\")\r\n",
    "    i = i.strip(\" \")\r\n",
    "    products.append(i)\r\n",
    "products"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.DataFrame(products)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Question 8 Weather forcast"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import lxml"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "page = requests.get(\"https://forecast.weather.gov/MapClick.php?lat=37.7772&lon=-122.4168\")\r\n",
    "soup = BeautifulSoup(page.content, 'lxml')\r\n",
    "seven_day = soup.find(id=\"seven-day-forecast\")\r\n",
    "forecast_items = seven_day.find_all(class_=\"tombstone-container\")\r\n",
    "tonight = forecast_items[0]\r\n",
    "print(tonight.prettify())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "period = tonight.find(class_=\"period-name\").get_text()\r\n",
    "short_desc = tonight.find(class_=\"short-desc\").get_text()\r\n",
    "temp = tonight.find(class_=\"temp\").get_text()\r\n",
    "print(period)\r\n",
    "print(short_desc)\r\n",
    "print(temp)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "img = tonight.find(\"img\")\r\n",
    "desc = img['title']\r\n",
    "print(desc)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "period_tags = seven_day.select(\".tombstone-container .period-name\")\r\n",
    "periods = [pt.get_text() for pt in period_tags]\r\n",
    "periods"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "short_descs = [sd.get_text() for sd in seven_day.select(\".tombstone-container .short-desc\")]\r\n",
    "temps = [t.get_text() for t in seven_day.select(\".tombstone-container .temp\")]\r\n",
    "descs = [d[\"title\"] for d in seven_day.select(\".tombstone-container img\")]\r\n",
    "print(short_descs)\r\n",
    "print(temps)\r\n",
    "print(descs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "weather = pd.DataFrame({\r\n",
    "    \"period\": periods,\r\n",
    "    \"short_desc\": short_descs,\r\n",
    "    \"temp\": temps,\r\n",
    "    \"desc\":descs\r\n",
    "})\r\n",
    "weather"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Question 9 Internshala"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_url(page_no):\r\n",
    "    url08 = 'https://internshala.com/internships/python%2Fdjango-internship/page-{}'.format(page_no)\r\n",
    "    return url08"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data =[]\r\n",
    "def gather_information():\r\n",
    "    data = {'Category':[],'company_name':[],'location':[],'start_date':[],'duration':[],'stipend':[],'apply_by':[],'detail':[]}\r\n",
    "    \r\n",
    "    for i in range(1,4):\r\n",
    "        res = requests.get(get_url(i))\r\n",
    "        markup = res.content\r\n",
    "        soup8 = BeautifulSoup(markup,\"lxml\")\r\n",
    "        posts = soup8.find_all('div',class_='container-fluid individual_internship')\r\n",
    "        for i in posts:\r\n",
    "            data['Category'].append(i.find('div',class_='heading_4_5').text)\r\n",
    "            data['company_name'].append(i.find('a',class_='link_display_like_text').text.strip())\r\n",
    "            data['location'].append(i.find('a',class_='location_link').text)\r\n",
    "            data['start_date'].append(i.find('div',class_='other_detail_item').find_next(id='start-date-first').text.strip().replace('Immediately',''))\r\n",
    "            data['duration'].append(i.find('div',class_='item_body',id=False).text.strip())\r\n",
    "            data['stipend'].append(i.find('span',class_='stipend').text)\r\n",
    "            data['apply_by'].append(i.find('div',class_='apply_by').find('div',class_='item_body').text)\r\n",
    "            data['detail'].append('https://internshala.com'+i.find('div',class_='button_container').a['href'])\r\n",
    "data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.DataFrame(data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df.to_csv('intern.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if __name__ == \"__main__\":\r\n",
    "    gather_information()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Question 10"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "url8=\"https://www.nobroker.in/flats-for-sale-in-bangalore_bangalore\"\r\n",
    "page10=requests.get(url8)\r\n",
    "page10"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "page10.content"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "soup101 = BeautifulSoup(page10.content,\"html.parser\")\r\n",
    "print(soup101.prettify())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "house_details=soup101.find_all('a',class_=\"nb__3CnI6\")\r\n",
    "house_details"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "house=soup101.find_all('div',class_=\"nb__2JHKO\")\r\n",
    "house"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "house_details = []\r\n",
    "for h in house:\r\n",
    "    h = h.get_text().replace('\\n',\"\")\r\n",
    "    h = h.strip(\" \")\r\n",
    "    house_details.append(h)\r\n",
    "house_details"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "emi = soup101.find_all('div',class_='nb__2NPHR')\r\n",
    "emi"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "emi_details = []\r\n",
    "for p in emi:\r\n",
    "    p = p.get_text().replace('\\n',\"\")\r\n",
    "    p = p.strip(\" \")\r\n",
    "    emi_details.append(p)\r\n",
    "emi_details"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df1=pd.DataFrame(house_details)\r\n",
    "df1.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df2=pd.DataFrame(emi_details)\r\n",
    "df2.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = pd.DataFrame()\r\n",
    "data['House']=df1\r\n",
    "data['Emi']=df2\r\n",
    "data.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gputest]",
   "language": "python",
   "name": "conda-env-gputest-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}